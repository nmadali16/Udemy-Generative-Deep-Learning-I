{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xDiu4nBZLO_"
   },
   "source": [
    "<center><h1>InterFaceGAN reimplementation</h1></center>\n",
    "\n",
    "This notebook contains a reimplementation of InterFaceGAN. It uses datasets generated by the notebook `ImageGenerator.ipynb` and labelled using a discriminator network trained on the CelebA dataset for 40 attributes (notebook `ImageDiscriminator.ipynb`).\n",
    "\n",
    "Imports, and mount Google Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOqo5GhlsSJu"
   },
   "source": [
    "Install StyleGAN2-ada-pytorch dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9280,
     "status": "ok",
     "timestamp": 1705065918409,
     "user": {
      "displayName": "Gurvan Richardeau",
      "userId": "08761909170587778949"
     },
     "user_tz": -60
    },
    "id": "k5C-dDBMFFa8",
    "outputId": "ed0a90fc-dd06-4974-dfde-916f55683605"
   },
   "outputs": [],
   "source": [
    "# This pip install avoids warnings.\n",
    "#!pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GbAbx_scmVZV"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import torch, pickle\n",
    "import functools\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEwPme44fWwi"
   },
   "source": [
    "# Retrieving StyleGAN2\n",
    "\n",
    "In order to edit the images, we need the StyleGAN2 model. This notebook assumes that stylegan2-ada-pytorch and the FFHQ pretrained weights are present in your Google Drive. If this is not the case, go to Part 1 of ImageGenerator.ipynb to download them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEBB0c1DQE8w"
   },
   "source": [
    "cd to YOUR PATH TO stylegan2-ada-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToV-nbP79bzY"
   },
   "source": [
    "Gurvan's path: /content/drive/MyDrive/UNIVERSITE/MVAmaterials/Projet_IIN/InterFaceGAN/stylegan2-ada-pytorch\n",
    "\n",
    "Victor's path: /content/drive/MyDrive/Projet_IIN/InterFaceGAN/stylegan2-ada-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 986,
     "status": "ok",
     "timestamp": 1705065922766,
     "user": {
      "displayName": "Gurvan Richardeau",
      "userId": "08761909170587778949"
     },
     "user_tz": -60
    },
    "id": "ICm9AJSza6gg",
    "outputId": "d441a2d7-d3aa-4acc-9dea-d40c35d7d8d2"
   },
   "outputs": [],
   "source": [
    "# add align_images.py\n",
    "!git clone https://github.com/rkuo2000/stylegan2-ada-pytorch\n",
    "%cd stylegan2-ada-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"pretrained\"):\n",
    "  !mkdir pretrained\n",
    "  %cd pretrained\n",
    "  !wget https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\n",
    "  %cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1Eg7am2-bqRy"
   },
   "outputs": [],
   "source": [
    "# Retrieving Generator\n",
    "device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device_name)\n",
    "\n",
    "with open('pretrained/ffhq.pkl', 'rb') as f:\n",
    "    G = pickle.load(f)['G_ema'].cuda()\n",
    "if device_name == \"cpu\":\n",
    "  G.synthesis.forward = functools.partial(G.synthesis.forward, force_fp32=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZFkXtiaACnt"
   },
   "source": [
    "# Retrieving labeled latent vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VIJeOEI8aaT2"
   },
   "source": [
    "**Adjust to your setup:** Paths to labels JSON file and archive containing latent vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QQ8S4NhLak0Y"
   },
   "outputs": [],
   "source": [
    "attribute_number =39 #[31, 39, 15, 20]\n",
    "Victor = False\n",
    "\n",
    "\n",
    "latent_vectors_path = '../test_ImageLatentCodes'\n",
    "labels_path = f'../test_dataset/Labels/att{str(attribute_number)}_labels.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Le volume dans le lecteur C n'a pas de nom.\n",
      " Le num‚ro de s‚rie du volume est 7E6D-8E43\n",
      "\n",
      " R‚pertoire de C:\\Users\\nmadali\\Nabil\\GANSpace-Reimplementation-main\\stylegan2-ada-pytorch-main\n",
      "\n",
      "26/05/2024  15:10    <DIR>          .\n",
      "26/05/2024  15:10    <DIR>          ..\n",
      "22/09/2023  13:45    <DIR>          .github\n",
      "22/09/2023  13:45                21 .gitignore\n",
      "26/05/2024  15:09           796ÿ765 all_components.pdf\n",
      "22/09/2023  13:45             8ÿ336 calc_metrics.py\n",
      "22/09/2023  13:45            17ÿ876 dataset_tool.py\n",
      "26/05/2024  14:45    <DIR>          dnnlib\n",
      "22/09/2023  13:45             1ÿ196 docker_run.sh\n",
      "22/09/2023  13:45               897 Dockerfile\n",
      "22/09/2023  13:45    <DIR>          docs\n",
      "26/05/2024  14:43       381ÿ624ÿ121 ffhq.pkl\n",
      "22/09/2023  13:45             5ÿ338 generate.py\n",
      "26/05/2024  15:11         1ÿ323ÿ840 layerwise.pdf\n",
      "22/09/2023  13:45            16ÿ504 legacy.py\n",
      "22/09/2023  13:45             4ÿ421 LICENSE.txt\n",
      "25/06/2024  11:46           185ÿ530 maxime_chauve.pt\n",
      "22/09/2023  13:45    <DIR>          metrics\n",
      "26/05/2024  15:09    <DIR>          PCA_vectors\n",
      "26/05/2024  15:09         1ÿ049ÿ950 PCA_vectorsW_PCA_on_100000_points.pt\n",
      "22/09/2023  13:45             8ÿ990 projector.py\n",
      "22/09/2023  13:45            25ÿ757 README.md\n",
      "22/09/2023  13:45             4ÿ891 style_mixing.py\n",
      "25/06/2024  11:45    <DIR>          SVM_vectors\n",
      "26/05/2024  14:45    <DIR>          torch_utils\n",
      "22/09/2023  13:45            24ÿ067 train.py\n",
      "22/09/2023  13:45    <DIR>          training\n",
      "              17 fichier(s)      385ÿ098ÿ500 octets\n",
      "              10 R‚p(s)  465ÿ824ÿ989ÿ184 octets libres\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pD1DS-FuQrMM"
   },
   "source": [
    "The following cell copies the latent vectors on the local machine as it would be much slower to manipulate vectors stored in Google Drive.\n",
    "\n",
    "Around 4min on Colab GPU with 15k tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1783,
     "status": "ok",
     "timestamp": 1705067836761,
     "user": {
      "displayName": "Gurvan Richardeau",
      "userId": "08761909170587778949"
     },
     "user_tz": -60
    },
    "id": "jnN89-Hfbm9w",
    "outputId": "fc43897d-cc43-4e77-e9a0-8819aaa38c57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:00, 3349.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the labels\n",
    "with open(labels_path, 'r') as f:\n",
    "  labels_dict = json.load(f)\n",
    "\n",
    "num_samples = len(labels_dict)\n",
    "dim = 512\n",
    "Z = torch.zeros((num_samples, dim)).to(device)\n",
    "y = np.zeros(num_samples, dtype=int)\n",
    "\n",
    "for i, (filename, label) in tqdm(enumerate(labels_dict.items())):\n",
    "  sample_number = int(filename[3:-4])\n",
    "  tensor_path = os.path.join(latent_vectors_path,f'tensor{sample_number}.pt')\n",
    "  Z[i] = torch.load(tensor_path, map_location=device)\n",
    "  y[i] = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BhYuw0uoDKre"
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8OkypS1ZmJ6"
   },
   "source": [
    "In the $\\mathcal{Z}$ latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1986,
     "status": "ok",
     "timestamp": 1705067838742,
     "user": {
      "displayName": "Gurvan Richardeau",
      "userId": "08761909170587778949"
     },
     "user_tz": -60
    },
    "id": "4dA9RNISjGkA",
    "outputId": "7845c3e2-ffe6-43eb-bdef-6b780d5306c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmadali\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "Z_for_SVM = Z.cpu().numpy()\n",
    "\n",
    "# Create and train the LinearSVC model\n",
    "linear_svm_Z = LinearSVC()\n",
    "linear_svm_Z.fit(Z_for_SVM, y)\n",
    "\n",
    "# Get the orthogonal vector of the hyperplane made by the svm.\n",
    "class_direction_Z = torch.Tensor(linear_svm_Z.coef_[0]) # a priori le vecteur est orienté de class 1 vers class 2\n",
    "\n",
    "Z_intercept = torch.Tensor(linear_svm_Z.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apHEmNcmZxiZ"
   },
   "source": [
    "In the $\\mathcal{W}$ latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jKyeAbzXTun1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmadali\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "W = G.mapping(Z, None)\n",
    "\n",
    "W_for_SVM = W[:,0,:].cpu().numpy()\n",
    "\n",
    "linear_svm_W = LinearSVC()\n",
    "linear_svm_W.fit(W_for_SVM, y)\n",
    "\n",
    "class_direction_W = torch.Tensor(linear_svm_W.coef_[0])\n",
    "\n",
    "W_intercept = torch.Tensor(linear_svm_W.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute_number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXD1iqSyfnBJ"
   },
   "source": [
    "Saving the normal vectors and intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('SVM_vectors'):\n",
    "    os.makedirs('SVM_vectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "aWBHdzo99z5r"
   },
   "outputs": [],
   "source": [
    "torch.save(class_direction_Z, f'SVM_vectors/class_direction_Z_on_3k_att{attribute_number}.pt')\n",
    "torch.save(class_direction_W, f'SVM_vectors/class_direction_W_on_3k_att{attribute_number}.pt')\n",
    "\n",
    "torch.save(Z_intercept, f'SVM_vectors/Z_intercept_on_3k_att{attribute_number}.pt')\n",
    "torch.save(W_intercept, f'SVM_vectors/W_intercept_on_3k_att{attribute_number}.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
